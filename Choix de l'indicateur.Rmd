---
title: "Choix de l'indicateur"
author: "Mathilda Alhamadah"
date: "2025-05-13"
output:
  html_document:
    toc: true             #table des matières
    toc_float: true       #table des matières toujours visible
    theme: bootstrap      #changer le thème de la page
    highlight: zenburn    #changer le thème des chunks
    
editor_options: 
  markdown: 
    wrap: 80
---

# 0. Recharger la fonction pour avoir les json en df

```{r packages, message=FALSE, warning=FALSE}
#install.packages("jsonlite")
#install.packages("curl")
#install.packages("lubridate")
library(jsonlite)
library(purrr)
library(curl)
library(dplyr)
library(lubridate)
library(tidyr)
```

## 0.1 Fonctions

```{r load_json_function}
#Function to load the data
load_json <- function(WD, file_name){
  
  #requirements :
            # WD & file_name are strings. 
  if (!is.character(WD) | !is.character(file_name)) {
    stop("Le working directory et le fichier doivent être des chaînes de caractère.")
  }
            # the file extension is .json
  if (!grepl("\\.json$", file_name)) {              #if the ending of the character is not ".json"
    stop("Le fichier doit être un fichier json.")   #stop
  }
  
  setwd(WD)                                #locate the data
  loaded_file <- fromJSON(file_name)       #load file
  return(loaded_file)                      #return file
}
```

```{r one_position_file_function}
one_position_file <- function(json_file,
                              threshold = 0.5,        #default = arbitrary
                              fox_id_limits = c(5,8), #default = like in the app
                              date_time_limits = c(10,28), #same remark
                              date_time_format = "%d_%m_%Y_%H_%M_%S" ) { #same remark
  
  #If Json file is not empty (there is a prediction)
  if(length(json_file$objects[[1]])>0) {
    
    nb_pred <- nrow(json_file$objects[[1]]) #get the number of predictions made by YOLO
    
    #Get file and most reliable prediction  
    dataframe_postures <- json_file$objects[[1]]                        #isolate the df with posture lines
    posture_most_confidence <- which.max(dataframe_postures$confidence) #identify most reliable posture
    data_new <- dataframe_postures[posture_most_confidence,] #new dataset with only the line that has the higher threshold
    
    data_new <- data_new %>% 
      mutate(number_of_predictions = nb_pred)      #get number of predictions
    
    #Check reliability
    if (max(json_file$objects[[1]]$confidence) < threshold){  #No line reliable enough
      print(paste("Confidence <", threshold*100, "% for file", json_file$filename,". Change threshold or do human check.")) #Change threshold/ human check
    }   
    
  }else{
    data_new <- json_file    #if empty Json : no change needed
    data_new <- data.frame(class_id = 3,                #number of the position = 3
                           name = "not visible",        #position value = not visible
                           relative_coordinates = NA,
                           confidence = NA,
                           number_of_predictions = 0)
  }
  
  #In any situation (if Json file is/is not empty)
    #add the filename
    data_new <- data_new %>%
      mutate(filename = json_file$filename)    #get filename

    #get the date and time
    str_datetime <- substr(data_new$filename, date_time_limits[1], date_time_limits[2]) #bonne partie de la string
    #/!\ à changer si la forme du fichier change. Là c'est pour des fichiers type f_ID4384_03_02_2023_19_46_12.jpg uniquement
    
    date_wrong_format <- strptime(str_datetime, format = date_time_format) #transformé en date et heure
    
    great_date <- format(date_wrong_format, "%d/%m/%Y %H:%M:%S") #date & heure au bon format
    
    great_date <- as.POSIXct(great_date, format = "%d/%m/%Y %H:%M:%S") #mettre en format datetime
    
    data_new <- data_new %>% 
      mutate(Date_Time = great_date)
    
   #get the fox id
    fox_id <- substr(data_new$filename, fox_id_limits[1], fox_id_limits[2])
    #/!\ ça aussi ça peut changer si format filenamechange
    
    data_new <- data_new %>% 
      mutate(fox_id = fox_id)
    
   #output  
    return(data_new = data_new)  #attention : il est renvoyé mais pas stocké ! 

}

```

```{r merge_postures_function}
# Fonction pour merge automatiquement toutes les lignes des dataframes en un seul dataframe
merge_postures <- function(list_df_postures) {
  return (dplyr::bind_rows(list_df_postures))
}

```

```{r from_json_to_df_function}

#Version opti 
from_json_to_df <- function(WD,
                            threshold = 0.34,            #being better than random
                            fox_id_limits = c(8, 11),    #default = YOLO output
                            date_time_limits = c(13, 31),             #same
                            date_time_format = "%d_%m_%Y_%H_%M_%S") { #same
  
  # Récupérer tous les fichiers JSON du dossier
  files <- list.files(path = WD, pattern = "\\.json$", full.names = TRUE)
  message("Chargement terminé. ", length(files), " fichiers ont été chargés.")
  
  # Charger et transformer chaque fichier
  list_df1line <- lapply(files, function(file) {
    data_loaded <- load_json(WD = WD, file = basename(file)) #basename : get only the file name from the whole working directory/ file path
    one_position_file(json_file = data_loaded,
                      threshold = threshold,
                      fox_id_limits = fox_id_limits,
                      date_time_limits = date_time_limits,
                      date_time_format = date_time_format)
  })
  
  # Fusionner les résultats
  df_merged <- merge_postures(list_df1line)
  message("Extraction terminée. ", length(files), " fichiers ont été fusionnés.")
  
  # Identifier et supprimer les lignes sans date
  na_rows <- is.na(df_merged$Date_Time)
  if (any(na_rows)) {
    message("Il y avait ", sum(na_rows), " fichiers sans date. Il s'agit des fichiers : ",
            paste(df_merged$filename[na_rows], collapse = ", "))
    df_merged <- df_merged[!na_rows, ]
  }
  
  return(df_merged)
}

```

## 0.2 Chargement des données

Datasets des 4 5 et 6 juillet 2022 :

```{r real_sample_to_work_on, eval=FALSE}
#Test on real data from YOLO (29000 files) : 04/07/2022
data_04_07_22 <- from_json_to_df("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1",
                threshold = 0.34,  #just to be sure we don't do worse than a random prediction = 1 chance/3 of getting the right prediction for the posture
                fox_id_limits = c(8,11),
                date_time_limits = c(13,31),
                date_time_format = "%d_%m_%Y_%H_%M_%S")

#renard4313 Video 1 06_07_2022 11_34_21 1
data_05_07_2022 <- from_json_to_df(WD = "F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 05_07_2022 08_13_03 1",
                        threshold = 0.34,  
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")

#renard4313 Video 1 06_07_2022 08_50_18 1
data_06_07_2022_part1 <- from_json_to_df(WD = "F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 06_07_2022 08_50_18 1",
                        threshold = 0.34,  
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")

#renard4313 Video 1 06_07_2022 11_34_21 1
data_06_07_2022_part2 <- from_json_to_df(WD = "F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 06_07_2022 11_34_21 1",
                        threshold = 0.34,  
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")



```

data_06_07_2022 : On a 615 frames avec une confiance \< 34% sur 35086, soit
1,8%. data_05_07_2022 : On a 403 frames avec une confiance \< 34% sur 38687,
soit 1,0%. data_04_07_2022 : on a 190 frames avec une confiance \< 34% sur
29415, soit 0,6%. C'est déjà mieux. Pourtant c'est le jour de l'inoculation :
bizarre.

## 0.3 Premières stats descriptives

```{r}
# Highest confidence rate when there is :

#3 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence) #0.54
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence)

#2 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence) #0.77
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence)

#1 prediction
mean(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence) #0.94
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence)
```

```{r}
library(jsonlite)

extract_confidence_differences <- function(directory) {
  files <- list.files(path = directory, pattern = "\\.json$", full.names = TRUE)
  confidence_diff_vector <- c()
  
  for (file in files) {
    json_data <- fromJSON(file)
    
    if (length(json_data$objects[[1]])>0) {   #if Json not empty
      objects <- json_data$objects[[1]]
      n_objects <- nrow(objects)
      
      # Si 2 prédictions exactement
      if (n_objects == 2) {
        
        diff <- abs(json_data$objects[[1]]$confidence[2]-
                      json_data$objects[[1]]$confidence[1])
        
        confidence_diff_vector <- c(confidence_diff_vector, diff)
      }
    }
  }
  
  return(confidence_diff_vector)
}

confidences_test <- extract_confidence_differences("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1")

boxplot(confidences_test)
```

## 0.4 Agrégation des données

On peut agréger facilement les dataframes.

```{r}
#ça merdouille au niveau du merge quand je mets les données du 6 juillet
rownames(data_04_07_2022) <- NULL
rownames(data_05_07_2022) <- NULL
rownames(data_06_07_2022_part1) <- NULL
rownames(data_06_07_2022_part2) <- NULL


any(duplicated(rownames(data_06_07_2022_part1)))
any(duplicated(rownames(data_06_07_2022_part2)))


class(data_06_07_2022_part1)
class(data_06_07_2022_part2)


datatest <- rbind(data_04_07_2022, data_05_07_2022, data_06_07_2022_part1, data_06_07_2022_part2)
  
test <- rbind(data_06_07_2022_part1, data_06_07_2022_part2)
test2 <- rbind(data_04_07_2022, data_05_07_2022)
test3 <- rbind(test, test2)

class(data_06_07_2022_part1$)
```

On peut ensuite filtrer le dataframe merge pour qu'il ne contienne que des
données entre 8h et 21h, et qu'il créé les secondes manquantes le cas échéant.

Fonction :

```{r}
rescale_8h_21h <- function(data){

# Keep only frames between 8am and 9pm
data_8h_21h_missing_seconds <- data %>%
  filter(format(Date_Time, "%H:%M:%S") >= "08:00:00" & format(Date_Time, "%H:%M:%S") <= "21:00:00")

# Create every second between 8am and 9pm for every fox id and day of recording
complete_data <- data_8h_21h_missing_seconds %>%
  mutate(date = as.Date(Date_Time)) %>%
  group_by(fox_id, date) %>%
  reframe(Date_Time = seq(from = as.POSIXct(paste(date[1], "08:00:00")),
                          to   = as.POSIXct(paste(date[1], "21:00:00")),
                          by   = "1 sec"))

# Merge it to the original data
data_8h_21h <- complete_data %>%
  left_join(data_8h_21h_missing_seconds, by = c("fox_id", "Date_Time"))

return (data_8h_21h)
  
}

#Test
#data_8h_21h_04_to_06_07_2022_test <- rescale_8h_21h(data_04_to_06_07_2022)
```

# 1. Mouvement dans la cage : centre du rectangle sur les axes x et y

## 1.1 Fréquence de mouvement du CG par unité de temps

```{r}
# Marche pas encore
# Number of movements made by time interval

movements_amount <- function(data, interval_seconds, movement_threshold = 0.01) {
  data <- data %>% arrange(Date_Time) #sort by date
  
  start_time <- min(data$Date_Time)   #oldest frame
  end_time <- max(data$Date_Time)     #newest frame
  
  #cut between these 2 frames depending on the time interval
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(                       #create the new df
    start_time = intervals[-length(intervals)],  #drop the last time
    end_time = intervals[-1]                     #drop the first time
  )
  
  #movement yes/no :
  data <- data %>% 
    mutate(movement_yes_no = ifelse( #if position difference between 2 times > 0,01
     abs(data$relative_coordinates$center_x - lag(data$relative_coordinates$center_x)) > movement_threshold
     | abs(data$relative_coordinates$center_y - lag(data$relative_coordinates$center_y)) > movement_threshold ,     
     1,                              #then movement
     0)                              #else : no movement)
    )
  
 df_counts <- df_counts %>% 
   rowwise() %>%
   mutate(movement_counts = sum(data[data$Date_Time > start_time & data$Date_Time <= end_time,]$movement_yes_no, #amount of movements = sum of the 1 (= movements)
                                na.rm = T),  #to avoid the 1st NA
          movement_proportion = ifelse(
            nrow(data[data$Date_Time > start_time & data$Date_Time <= end_time,])!=0, #if there is at least 1 observation for this timestep
            movement_counts/nrow(data[data$Date_Time > start_time & data$Date_Time <= end_time,]), #proportion = n/N
            0   #else : proportion = 0
          )
     )


return(df_counts)

}

df_movement <- movements_amount(data = data, interval_seconds = 3600)
```

```{r}

#code copilot, à voir
calculate_distances <- function(data, interval) {
  
  # Calculer la distance entre deux points
  calculate_distance <- function(x1, y1, x2, y2) {
    sqrt((x2 - x1)^2 + (y2 - y1)^2)
  }
  
  # Ajouter une colonne pour la distance parcourue chaque seconde
  data <- data %>%
    arrange(Date_Time) %>%
    mutate(
      distance = sqrt((relative_coordinates$center_x - lag(relative_coordinates$center_x))^2 + 
                      (relative_coordinates$center_y - lag(relative_coordinates$center_y))^2),
      time_diff = as.numeric(difftime(Date_Time, lag(Date_Time), units = "secs"))
    ) %>%
    filter(!is.na(distance) & time_diff == 1)  #should not happen ?
  
  # Calculer la somme des distances et la vitesse moyenne pour chaque intervalle
  result <- data %>%
    mutate(interval_group = floor(as.numeric(difftime(Date_Time, min(Date_Time), units = "secs")) / interval)) %>%
    group_by(interval_group) %>%
    summarise(
      total_distance = sum(distance, na.rm = TRUE),
      average_speed = total_distance / interval
    )
  
  return(result)
}

# Exemple d'utilisation
# data <- read.csv("path_to_your_data.csv")
# interval <- 60 # par exemple, 60 secondes
# result <- calculate_distances(data, interval)
# print(result)

calculate_distances(data=data,interval=600)

```

## 1.2 Intensité des mouvements

## 1.3 Vitesse des mouvements

# 2. Alternance des positions assis/ debout/ couché

## 2.1 Fréquence de chaque position par unité de temps

### 2.1.1 Function

```{r}

# Frequency of positions lying/ sitting/ standing by timestep (chosen)
frequency_position <- function(data, interval_seconds) {
  data <- data %>% arrange(Date_Time) #sort by date
  
  start_time <- min(data$Date_Time)   #oldest frame
  end_time <- max(data$Date_Time)     #newest frame
  
  #cut between these 2 frames depending on the time interval
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(                       #create the new df
    start_time = intervals[-length(intervals)],  #drop the last time
    end_time = intervals[-1]                     #drop the first time
  )
  
  df_counts <- df_counts %>%
    rowwise() %>%               #for each line
    mutate(
      lying = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 0),            #count lying
      standing = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 1),            #count standing
      sitting = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 2),            #count sitting
      not_visible = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 3)             #count not visible
    )
  
  return(df_counts)
}

# Test pour 900 secondes (15 minutes)
frequency_position_04_07_2022 <- frequency_position(data = data_04_07_2022, interval_seconds = 600)

frequency_position_04_to_06_07_2022 <- frequency_position(data = data_04_to_06_07_2022, interval_seconds = 600)

min(data_04_to_06_07_2022$Date_Time)
```

### 2.1.2 Chart

```{r}
#install.packages("ggplot2")
#install.packages("tidyr")
library(ggplot2)
library(tidyr)
library(dplyr)

#put data in the long format (instead of wide) : pivot function
frequency_position_04_07_22_PIVOT <- frequency_position_04_07_22[,-2] %>% #drop the end_time column
  pivot_longer(
    cols = !start_time, 
    names_to = "Posture", 
    values_to = "Count"
  )

#chart
ggplot(data = frequency_position_04_07_22_PIVOT,
       aes(fill = Posture, y = Count, x = start_time)) +         #start_time as x variable
  geom_bar(position = "stack", stat = "identity") +              #stacked bars, no %
  ggtitle("Fox4313's posture every 10min on day 04/07/2022") +   #title
  xlab("Time of the day") +
  ylab("Amount of seconds spent in this posture") +                              
  scale_fill_manual(breaks = c("lying", "sitting", "standing", "not_visible"), #re-order legend
                    values = c("lying" = "lightgreen", #change legend colors
                               "sitting" = "orange",
                               "standing" = "tomato",
                               "not_visible" = "lightgrey"))


#OR : 
# ggplot(data = frequency_position_04_07_22_PIVOT,
#        aes(fill = Posture, y = Count, x = start_time)) + 
#   geom_col(aes(fill = Posture)) 
  
```

## 2.2 Quantification de chaque position et addition

Pour le moment on a 0-allongé 1-debout 2-couché. On veut plutôt 0-allongé
1-assis 2-debout pour quantifier l'activité en fonction de la posture détectée.
Mais finalement il nous faudrait plus un indicateur qui va entre 0 et 1 (peut
être transformé en %) -\> plutôt faire 0,0.5 et 1 :

### 2.2.1 Function

```{r}
#Change posture code to lying-sitting-standing (instead of lying-standing-sitting)
recoding_posture <- function(data){
  data <- data %>% 
  mutate(increasing_code = case_when(name=="lying" ~ 0,
                                   name=="sitting" ~ 0.5,
                                   name=="standing" ~ 1,
                                   name=="not visible" ~ NA, #to avoid having it in the sum
                                   TRUE ~ NA))
}

#Test data 04/07/2022
data_04_07_22_increasing_code <- recoding_posture(data_04_07_22)
```

```{r}
amount_activity <- function(data, interval_seconds) {
  data <- data %>% arrange(Date_Time)
  
  start_time <- min(data$Date_Time)
  end_time <- max(data$Date_Time)
  
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(
    interval_start = intervals[-length(intervals)],
    interval_end = intervals[-1]
  )
  
  df_counts <- df_counts %>%
    rowwise() %>%
    mutate(
      total_activity = sum(data$increasing_code[data$Date_Time >= interval_start & data$Date_Time < interval_end], na.rm = TRUE), #not counting NAs
      activity_proportion = ifelse(
        total_activity != 0,
        total_activity / nrow(data[data$Date_Time >= interval_start & data$Date_Time < interval_end, ]),
        0
      )
    )
  
  return(df_counts)
}


# Test toutes les 600 secondes (10 minutes)
amount_activity_04_07_2022 <- amount_activity(data = data_04_07_22_increasing_code,
                                              interval_seconds = 600)

```

### 2.2.2 Chart

```{r}
#barchart classique pour l'effectif (en secondes)
ggplot(data = frequency_position_04_07_22_PIVOT,
       aes(fill = Posture, y = Count, x = start_time)) +         #start_time as x variable
  geom_bar(position = "stack", stat = "identity") +              #stacked bars, no %
  ggtitle("Fox4313's posture every 10min on day 04/07/2022") +   #title
  xlab("Time of the day") +
  ylab("Amount of seconds spent in this posture") +                              
  scale_fill_manual(breaks = c("lying", "sitting", "standing", "not_visible"), #re-order legend
                    values = c("lying" = "lightgreen", #change legend colors
                               "sitting" = "orange",
                               "standing" = "tomato",
                               "not_visible" = "lightgrey"))

ggplot(data = amount_activity_04_07_2022, aes(interval_start)) +
  geom_bar()

```
