---
title: "Choix de l'indicateur"
author: "Mathilda Alhamadah"
date: "2025-05-13"
output:
  html_document:
    toc: true             #table des matières
    toc_float: true       #table des matières toujours visible
    theme: bootstrap      #changer le thème de la page
    highlight: zenburn    #changer le thème des chunks
    
editor_options: 
  markdown: 
    wrap: 80
---

# 0. Recharger la fonction pour avoir les json en df

```{r packages, message=FALSE, warning=FALSE}
#install.packages("jsonlite")
#install.packages("curl")
#install.packages("lubridate")
library(jsonlite)
library(purrr)
library(curl)
library(dplyr)
library(lubridate)
```

```{r load_json_function}
#Function to load the data
load_json <- function(WD, file_name){
  
  #requirements :
            # WD & file_name are strings. 
  if (!is.character(WD) | !is.character(file_name)) {
    stop("Le working directory et le fichier doivent être des chaînes de caractère.")
  }
            # the file extension is .json
  if (!grepl("\\.json$", file_name)) {              #if the ending of the character is not ".json"
    stop("Le fichier doit être un fichier json.")   #stop
  }
  
  setwd(WD)                                #locate the data
  loaded_file <- fromJSON(file_name)       #load file
  return(loaded_file)                      #return file
}
```

```{r one_position_file_function}
one_position_file <- function(json_file,
                              threshold = 0.5,        #default = arbitrary
                              fox_id_limits = c(5,8), #default = like in the app
                              date_time_limits = c(10,28), #same remark
                              date_time_format = "%d_%m_%Y_%H_%M_%S" ) { #same remark
  
  #If Json file is not empty (there is a prediction)
  if(length(json_file$objects[[1]])>0) {
    
    nb_pred <- nrow(json_file$objects[[1]]) #get the number of predictions made by YOLO
    
    #Get file and most reliable prediction  
    dataframe_postures <- json_file$objects[[1]]                        #isolate the df with posture lines
    posture_most_confidence <- which.max(dataframe_postures$confidence) #identify most reliable posture
    data_new <- dataframe_postures[posture_most_confidence,] #new dataset with only the line that has the higher threshold
    
    data_new <- data_new %>% 
      mutate(number_of_predictions = nb_pred)      #get number of predictions
    
    #Check reliability
    if (max(json_file$objects[[1]]$confidence) < threshold){  #No line reliable enough
      print(paste("Confidence <", threshold*100, "% for file", json_file$filename,". Change threshold or do human check.")) #Change threshold/ human check
    }   
    
  }else{
    data_new <- json_file    #if empty Json : no change needed
    data_new <- data.frame(class_id = 3,                #number of the position = 3
                           name = "not visible",        #position value = not visible
                           relative_coordinates = NA,
                           confidence = NA,
                           number_of_predictions = 0)
  }
  
  #In any situation (if Json file is/is not empty)
    #add the filename
    data_new <- data_new %>%
      mutate(filename = json_file$filename)    #get filename

    #get the date and time
    str_datetime <- substr(data_new$filename, date_time_limits[1], date_time_limits[2]) #bonne partie de la string
    #/!\ à changer si la forme du fichier change. Là c'est pour des fichiers type f_ID4384_03_02_2023_19_46_12.jpg uniquement
    
    date_wrong_format <- strptime(str_datetime, format = date_time_format) #transformé en date et heure
    
    great_date <- format(date_wrong_format, "%d/%m/%Y %H:%M:%S") #date & heure au bon format
    
    great_date <- as.POSIXct(great_date, format = "%d/%m/%Y %H:%M:%S") #mettre en format datetime
    
    data_new <- data_new %>% 
      mutate(Date_Time = great_date)
    
   #get the fox id
    fox_id <- substr(data_new$filename, fox_id_limits[1], fox_id_limits[2])
    #/!\ ça aussi ça peut changer si format filenamechange
    
    data_new <- data_new %>% 
      mutate(fox_id = fox_id)
    
   #output  
    return(data_new = data_new)  #attention : il est renvoyé mais pas stocké ! 

}

```

```{r merge_postures_function}
# Fonction pour merge automatiquement toutes les lignes des dataframes en un seul dataframe
merge_postures <- function(list_df_postures) {
  return (dplyr::bind_rows(list_df_postures))
}

```

```{r from_json_to_df_function}

from_json_to_df <- function(WD,
                            threshold = 0.6,
                            fox_id_limits = c(5,8),   #default = for the app outputs
                            date_time_limits = c(10,28),                #same
                            date_time_format = "%d_%m_%Y_%H_%M_%S")  {  #same
  
  # Récuperer tous les fichiers Json du dossier
  setwd(WD)        #Set WD
  files <- list.files(pattern = ".json") #get Json files
  print(paste("Chargement terminé. ",length(files), " fichiers ont été chargés."))
  
  # Créer la liste vide de dataframes et la variable à incrémenter
  list_df1line = list()  #empty list
  i = 0  #increment
  
  # Boucle pour chaque fichier
  for (file in files) {
    
    # Appliquer la fonction load_json à tous les éléments du dossier
    data_loaded <- load_json(WD = WD, file = file)
    
    # Appliquer one_position_file à tous les nouveaux dataframes
    data_1line <- one_position_file(json_file = data_loaded,
                                    threshold = threshold,
                                    fox_id_limits = fox_id_limits,
                                    date_time_limits = date_time_limits,
                                    date_time_format = date_time_format)
  
    # Tous les mettre dans une liste 
    list_df1line[[i+1]] <- data_1line
    
    i <- i+1 #next file
  }
  
  # Appliquer le merge sur la liste et récup le dataframe mergé
  df_merged <- merge_postures(list_df1line) 
  print(paste("Extraction terminée. ", i, "fichiers ont été fusionnés."))
  
  return(df_merged)
  
}
```


```{r example_sample_to_work_on}
# Récupérer tous les fichiers json que Julie m'a donnés
df_not_clean <- from_json_to_df("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
                            fox_id_limits = c(9,12),
                            date_time_limits = c(14,32),
                            date_time_format = "%Y-%m-%d-%Hh%Mm%S")

# Supprimer ceux qui ont des formats chiants (date illisible)
data <- df_not_clean[  !is.na(df_not_clean$Date_Time) &
                       !is.na(as.numeric(df_not_clean$fox_id)) &
                       (df_not_clean$class_id == 0 |
                       df_not_clean$class_id == 1 |
                       df_not_clean$class_id == 2) ,
                     ]

rm(df_not_clean)

# Trier par date
data <- data %>% arrange(Date_Time) 
```

```{r real_sample_to_work_on}
#Test on real data from YOLO (29000 files) : 04/07/2022
data_04_07_22 <- from_json_to_df("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1",
                threshold = 0.34,  #just to be sure we don't do worse than a random prediction
                fox_id_limits = c(8,11),
                date_time_limits = c(13,31),
                date_time_format = "%d_%m_%Y_%H_%M_%S")

#renard4313 Video 1 06_07_2022 11_34_21 1
data_06_07_2022 <- from_json_to_df(WD = "F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 06_07_2022 11_34_21 1",
                        threshold = 0.34,  
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")

```

data_06_07_2022 : On a 615 frames avec une confiance < 34% sur 35086, soit 1,8%.
data_04_07_2022 : on a 190 frames avec une confiance < 34% sur 29415, soit 0,6%. C'est déjà mieux. Pourtant c'est le jour de l'inoculation : bizarre.

```{r}
# Highest confidence rate when there is :

#3 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence) #0.54
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence)

#2 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence) #0.77
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence)

#1 prediction
mean(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence) #0.94
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence)
```


```{r}
library(jsonlite)

extract_confidence_differences <- function(directory) {
  files <- list.files(path = directory, pattern = "\\.json$", full.names = TRUE)
  confidence_diff_vector <- c()
  
  for (file in files) {
    json_data <- fromJSON(file)
    
    if (length(json_data$objects[[1]])>0) {   #if Json not empty
      objects <- json_data$objects[[1]]
      n_objects <- nrow(objects)
      
      # Si 2 prédictions exactement
      if (n_objects == 2) {
        
        diff <- abs(json_data$objects[[1]]$confidence[2]-
                      json_data$objects[[1]]$confidence[1])
        
        confidence_diff_vector <- c(confidence_diff_vector, diff)
      }
    }
  }
  
  return(confidence_diff_vector)
}

confidences_test <- extract_confidence_differences("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1")

boxplot(confidences_test)
```





# 1. Mouvement dans la cage : centre du rectangle sur les axes x et y

## 1.1 Fréquence de mouvement du CG par unité de temps

```{r}
# Number of movements made by time interval

movements_amount <- function(data, interval_seconds, movement_threshold = 0.01) {
  data <- data %>% arrange(Date_Time) #sort by date
  
  start_time <- min(data$Date_Time)   #oldest frame
  end_time <- max(data$Date_Time)     #newest frame
  
  #cut between these 2 frames depending on the time interval
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(                       #create the new df
    start_time = intervals[-length(intervals)],  #drop the last time
    end_time = intervals[-1]                     #drop the first time
  )
  
  #movement yes/no :
  data <- data %>% 
    mutate(movement_yes_no = ifelse( #if position difference between 2 times > 0,01
     abs(data$relative_coordinates$center_x - lag(data$relative_coordinates$center_x)) > movement_threshold
     | abs(data$relative_coordinates$center_y - lag(data$relative_coordinates$center_y)) > movement_threshold ,     
     1,                              #then movement
     0)                              #else : no movement)
    )
  
 df_counts <- df_counts %>% 
   rowwise() %>%
   mutate(movement_counts = sum(data[data$Date_Time > start_time & data$Date_Time <= end_time,]$movement_yes_no, #amount of movements = sum of the 1 (= movements)
                                na.rm = T),  #to avoid the 1st NA
          movement_proportion = ifelse(
            nrow(data[data$Date_Time > start_time & data$Date_Time <= end_time,])!=0, #if there is at least 1 observation for this timestep
            movement_counts/nrow(data[data$Date_Time > start_time & data$Date_Time <= end_time,]), #proportion = n/N
            0   #else : proportion = 0
          )
     )


return(df_counts)

}

df_movement <- movements_amount(data = data, interval_seconds = 3600)
```

```{r}

#code copilot, à voir
calculate_distances <- function(data, interval) {
  
  # Calculer la distance entre deux points
  calculate_distance <- function(x1, y1, x2, y2) {
    sqrt((x2 - x1)^2 + (y2 - y1)^2)
  }
  
  # Ajouter une colonne pour la distance parcourue chaque seconde
  data <- data %>%
    arrange(Date_Time) %>%
    mutate(
      distance = sqrt((relative_coordinates$center_x - lag(relative_coordinates$center_x))^2 + 
                      (relative_coordinates$center_y - lag(relative_coordinates$center_y))^2),
      time_diff = as.numeric(difftime(Date_Time, lag(Date_Time), units = "secs"))
    ) %>%
    filter(!is.na(distance) & time_diff == 1)  #should not happen ?
  
  # Calculer la somme des distances et la vitesse moyenne pour chaque intervalle
  result <- data %>%
    mutate(interval_group = floor(as.numeric(difftime(Date_Time, min(Date_Time), units = "secs")) / interval)) %>%
    group_by(interval_group) %>%
    summarise(
      total_distance = sum(distance, na.rm = TRUE),
      average_speed = total_distance / interval
    )
  
  return(result)
}

# Exemple d'utilisation
# data <- read.csv("path_to_your_data.csv")
# interval <- 60 # par exemple, 60 secondes
# result <- calculate_distances(data, interval)
# print(result)

calculate_distances(data=data,interval=600)

```

## 1.2 Intensité des mouvements

## 1.3 Vitesse des mouvements

# 2. Alternance des positions assis/ debout/ couché

## 2.1 Fréquence de chaque position par unité de temps

```{r}

# Frequency of positions lying/ sitting/ standing by timestep (chosen)
frequency_position <- function(data, interval_seconds) {
  data <- data %>% arrange(Date_Time) #sort by date
  
  start_time <- min(data$Date_Time)   #oldest frame
  end_time <- max(data$Date_Time)     #newest frame
  
  #cut between these 2 frames depending on the time interval
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(                       #create the new df
    start_time = intervals[-length(intervals)],  #drop the last time
    end_time = intervals[-1]                     #drop the first time
  )
  
  df_counts <- df_counts %>%
    rowwise() %>%               #for each line
    mutate(
      count_0 = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 0),            #count lying
      count_1 = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 1),            #count standing
      count_2 = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 2)             #count sitting
    )
  
  return(df_counts)
}

# Test pour 600 secondes (10 minutes)
new_df <- frequency_position(data = data, interval_seconds = 600)

```

## 2.2 Quantification de chaque position et addition

Pour le moment on a 0-allongé 1-debout 2-couché. On veut plutôt 0-allongé
1-assis 2-debout pour quantifier l'activité en fonction de la posture détectée.

```{r}
#Change position code
data <- data %>% 
  mutate(position_code = case_when(name=="lying" ~ 0,
                                   name=="sitting" ~ 1,
                                   name=="standing" ~ 2,
                                   TRUE ~ NA
  ))

# Amount of activity in positions by timestep (chosen)
amount_activity <- function(data, interval_seconds) {
  data <- data %>% arrange(Date_Time) #sort by date
  
  start_time <- min(data$Date_Time)   #oldest frame
  end_time <- max(data$Date_Time)     #newest frame
  
  #cut between these 2 frames depending on the time interval
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(                       #create the new df
    start_time = intervals[-length(intervals)],  #drop the last time
    end_time = intervals[-1]                     #drop the first time
  )
  
  df_counts <- df_counts %>%
    rowwise() %>%               #for each line
    mutate(
      total_activity = sum(data[data$Date_Time >= start_time #sum position scores 
                          & data$Date_Time < end_time,]$position_code),            
      activity_proportion = ifelse(total_activity != 0, #if not always lying
                                   total_activity/nrow(data[data$Date_Time >= start_time & data$Date_Time < end_time,]),                       #compute proportion
                                   0)              #else : proportion = 0
    )
  
  return(df_counts)
}

# Test pour 600 secondes (10 minutes)
new_df2 <- amount_activity(data = data, interval_seconds = 600)

# Test pour 24h = 86400s

df_24h <- amount_activity(data = data, interval_seconds = 86400)
```
