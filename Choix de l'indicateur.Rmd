---
title: "Choix de l'indicateur"
author: "Mathilda Alhamadah"
date: "2025-05-13"
output:
  html_document:
    toc: true             #table des matières
    toc_float: true       #table des matières toujours visible
    theme: bootstrap      #changer le thème de la page
    highlight: zenburn    #changer le thème des chunks
    
editor_options: 
  markdown: 
    wrap: 80
---

# 0. Reload function to get Jsons in dataframes

```{r packages, message=FALSE, warning=FALSE}
#install.packages("jsonlite")
#install.packages("curl")
#install.packages("lubridate")
library(jsonlite)
library(purrr)
library(curl)
library(dplyr)
library(lubridate)
library(tidyr)
library(ggplot2)
```

## 0.1 Functions

```{r load_json_function}
#Function to load the data
load_json <- function(WD, file_name){
  
  #requirements :
            # WD & file_name are strings. 
  if (!is.character(WD) | !is.character(file_name)) {
    stop("Le working directory et le fichier doivent être des chaînes de caractère.")
  }
            # the file extension is .json
  if (!grepl("\\.json$", file_name)) {              #if the ending of the character is not ".json"
    stop("Le fichier doit être un fichier json.")   #stop
  }
  
  setwd(WD)                                #locate the data
  loaded_file <- fromJSON(file_name)       #load file
  return(loaded_file)                      #return file
}
```

```{r one_position_file_function}
#Keep only one posture (= one line) per second

one_position_file <- function(
    json_file,
    threshold = 0.34,            #default = better prediction than random classification (=1/3 because there are 3 postures)
    fox_id_limits = c(8,11),     #default = YOLO output
    date_time_limits = c(13,31), #same
    date_time_format = "%d_%m_%Y_%H_%M_%S" ) { #same
  

  nb_pred <- length(json_file$objects[[1]]) #keep the number of predictions
  
#If Json file is not empty (there is at least 1 prediction)
  if(nb_pred >0) {
    
    nb_pred <- nrow(json_file$objects[[1]])  #get how many predictions are made by YOLO
    
    #Get file and most reliable prediction 
    
  #isolate the df with posture lines + sort by confidence (higher on line 1)
    dataframe_postures <- json_file$objects[[1]] %>% 
      arrange(desc(confidence))
  #identify the most reliable posture
    posture_most_confidence <- dataframe_postures[1,]
    
  #identify the 2nd most reliable posture (if existing)
    posture_2nd_most_confidence <- ifelse(nb_pred >= 2,
                                          dataframe_postures[2,],
                                          NA) #if <2 pred : no 2nd posture
  #new dataset with only the most confident prediction (1 line)
    data_new <- posture_most_confidence  #get the most confident line
    
    #get the gap between the 2 most reliable predictions (if there are 2)
      data_new <- data_new %>% 
        mutate(
          confidence_gap = case_when(
          #if only 1 prediction : confidence_gap = 1 (highest certainty gap)
            nb_pred == 1 ~ 1, 
          #if 2+ predictions : confidence_gap = difference btw 2 highest pred
            nb_pred >= 2 ~ dataframe_postures[1, "confidence"] - dataframe_postures[2, "confidence"]),
          
      #get number of predictions
          number_of_predictions = nb_pred)

    #Check reliability
    if (max(json_file$objects[[1]]$confidence) < threshold){  #No line reliable enough
      print(paste("Confidence <", threshold*100, "% for file", json_file$filename,". Change threshold or do human check.")) #Change threshold/ human check
      
    }
    
# If Json file is empty (0 predictions)
  }else{
    data_new <- json_file                           #no change needed
    data_new <- data.frame(class_id = 3,            #position number 3
                           name = "not visible",    #position name = not visible
                           relative_coordinates = NA, #no coordinates
                           confidence = NA,           #no confidence
                           confidence_gap = NA,       #no confidence gap
                           number_of_predictions = 0) #no predictions
  }
  
#In any situation (if Json file is/is not empty)
    #add the filename
    data_new <- data_new %>%
      mutate(filename = json_file$filename) #get filename
    
    #get the date and time
    str_datetime <- substr(data_new$filename, date_time_limits[1], date_time_limits[2]) #get the datetime part from the string
    
    date_wrong_format <- strptime(str_datetime, format = date_time_format) #change the date into a datetime format (but not the right one : default)
    
    great_date <- format(date_wrong_format, "%d/%m/%Y %H:%M:%S") #date & hour in the right format
    
    great_date <- as.POSIXct(great_date, format = "%d/%m/%Y %H:%M:%S") #convert it into POSIXct (a great format for datetime data)
    
    data_new <- data_new %>% 
      mutate(Date_Time = great_date) #add variable
    
   #get the fox id
    fox_id <- substr(data_new$filename, fox_id_limits[1], fox_id_limits[2])
    
    data_new <- data_new %>% 
      mutate(fox_id = fox_id)        #add variable

    
   #output  
    return(data_new = data_new)  

}

```

```{r merge_postures_function}
# Fonction pour merge automatiquement toutes les lignes des dataframes en un seul dataframe
merge_postures <- function(list_df_postures) {
  return (dplyr::bind_rows(list_df_postures))
}

```

```{r from_json_to_df_function}

from_json_to_df <- function(WD,
                            threshold = 0.34,          #being better than random
                            fox_id_limits = c(8,11),   #default = YOLO output
                            date_time_limits = c(13,31),                #same
                            date_time_format = "%d_%m_%Y_%H_%M_%S")  {  #same
  
  # Get all the JSON files from the folder
  setwd(WD)                              #Set WD
  files <- list.files(pattern = ".json") #get Json files
  print(paste("Chargement terminé. ",length(files), " fichiers ont été chargés."))
  
  # Create empty list of dataframes & variable to increment
  list_df1line = list()  #empty list
  i = 0                  #increment
  
  # Loop for each file
  for (file in files) {
    
    # Apply function load_json to every file of the folder
    data_loaded <- load_json(WD = WD, file = file)
    
    # Apply function one_position_file to every new dataframe
    data_1line <- one_position_file(json_file = data_loaded,
                                    threshold = threshold,
                                    fox_id_limits = fox_id_limits,
                                    date_time_limits = date_time_limits,
                                    date_time_format = date_time_format)
  
    # Put them all in a list
    list_df1line[[i+1]] <- data_1line
    
    i <- i+1 #next file
  }
  
  # Merge this list's elements & get the dataframe
  df_merged <- merge_postures(list_df1line) 
  

  # Print end of the run
  print(paste("Extraction terminée. ", i, "fichiers ont été fusionnés."))
  
  # Spot files with NA date (check if they are prediction files, 1 of them is created at every YOLO run)
  print(paste("Il y avait", nrow(df_merged[is.na(df_merged$Date_Time),]), "fichiers sans date. Il s'agit des fichiers : ", df_merged[is.na(df_merged$Date_Time),]$filename))
  
  # Delete those files
  df_merged <- df_merged[!is.na(df_merged$Date_Time),]
  
  # Return data
  return(df_merged)
  
}

```

```{r}
# Confidence gap when 2 predictions

extract_confidence_differences <- function(directory) {
  
  # For all the Json files in the directory 
  files <- list.files(path = directory, pattern = "\\.json$", full.names = TRUE)
  confidence_diff_vector <- c() #empty vector
  
  for (file in files) {
    json_data <- fromJSON(file)
    
    # If Json not empty
    if (length(json_data$objects[[1]])>0) { 
      objects <- json_data$objects[[1]]
      n_objects <- nrow(objects)
      
      # If 2 predictions exactly
      if (n_objects == 2) {
        
        # Compute confidence difference
        diff <- abs(json_data$objects[[1]]$confidence[2]-
                      json_data$objects[[1]]$confidence[1])
        
        # Put it in a vector
        confidence_diff_vector <- c(confidence_diff_vector, diff)
      }
    }
  }
  # Return it
  return(confidence_diff_vector)
}

confidences_test <- extract_confidence_differences("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1")

# Boxplot
boxplot(confidences_test)
```

```{r}
# Aggregate dataframes 
data_04_to_06_07_2022 <- bind_rows(data_04_07_2022, data_05_07_2022, data_06_07_2022_part1, data_06_07_2022_part2)
```

```{r function_rescale_8h_21h}
# Adapt dataframe so that there is only (and mandatory) data between 8h and 21h. No matter if we have to create NAs/ loose data.

rescale_8h_21h <- function(data){

# Keep only frames between 8am and 9pm
data_8h_21h_missing_seconds <- data %>%
  filter(format(Date_Time, "%H:%M:%S") >= "08:00:00" & format(Date_Time, "%H:%M:%S") <= "21:00:00")

# Create every second between 8am and 9pm for every fox id and day of recording
complete_data <- data_8h_21h_missing_seconds %>%
  mutate(date = as.Date(Date_Time)) %>%
  group_by(fox_id, date) %>%
  reframe(Date_Time = seq(from = as.POSIXct(paste(date[1], "08:00:00")),
                          to   = as.POSIXct(paste(date[1], "21:00:00")),
                          by   = "1 sec"))

# Merge it to the original data
data_8h_21h <- complete_data %>%
  left_join(data_8h_21h_missing_seconds, by = c("fox_id", "Date_Time"))


return (data_8h_21h)
  
}
```

```{r function_add_compressed_time_variable}
# Useful to skip the 21h-8h gap when plotting/ analyzing
add_compressed_time_variable <- function(data) {
  data$compressed_time <- seq_len(nrow(data))-1 #-1 to make it start with 0
  return(data)
}
```

## 0.2 Load data

Datasets from 4 5 and 6 of July 2022 :

```{r real_sample_to_work_on, eval=FALSE}
  
  # Load data

#Test on real data from YOLO (29000 files) : 04/07/2022
data_04_07_22 <- from_json_to_df("H:/Etude 1 Video plus implants/Images et prédictions YOLO/renard4313 Video 1 04_07_2022 10_47_16 1",
                threshold = 0.34,  #just to be sure we don't do worse than a random prediction = 1 chance/3 of getting the right prediction for the posture
                fox_id_limits = c(8,11),
                date_time_limits = c(13,31),
                date_time_format = "%d_%m_%Y_%H_%M_%S")

#renard4313 Video 1 05_07_2022 08_13_03 1
data_05_07_2022 <- from_json_to_df(WD = "H:/Etude 1 Video plus implants/Images et prédictions YOLO/renard4313 Video 1 05_07_2022 08_13_03 1",
                        threshold = 0.34,  
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")

#renard4313 Video 1 06_07_2022 08_50_18 1
data_06_07_2022_part1 <- from_json_to_df(WD = "H:/Etude 1 Video plus implants/Images et prédictions YOLO/renard4313 Video 1 06_07_2022 08_50_18 1",
                        threshold = 0.34,  
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")

#renard4313 Video 1 06_07_2022 11_34_21 1
data_06_07_2022_part2 <- from_json_to_df(WD = "H:/Etude 1 Video plus implants/Images et prédictions YOLO/renard4313 Video 1 06_07_2022 11_34_21 1",
                        threshold = 0.34,  
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")

  # Merge data
data_04_to_06_07_2022 <- rbind(data_04_07_2022, data_05_07_2022, data_06_07_2022_part1, data_06_07_2022_part2)

  # Rescale data
data_8h_21h_04_to_06_07_2022 <- rescale_8h_21h(data_04_to_06_07_2022)
```

## 0.3 First descriptive statistics

```{r}
# Highest confidence rate when there is :

#3 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence) #0.54
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence)

#2 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence) #0.77
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence)

#1 prediction
mean(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence) #0.94
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence)
```

```{r}
extract_confidence_differences <- function(directory) {
  files <- list.files(path = directory, pattern = "\\.json$", full.names = TRUE)
  confidence_diff_vector <- c()
  
  for (file in files) {
    json_data <- fromJSON(file)
    
    if (length(json_data$objects[[1]])>0) {   #if Json not empty
      objects <- json_data$objects[[1]]
      n_objects <- nrow(objects)
      
      # Si 2 prédictions exactement
      if (n_objects == 2) {
        
        diff <- abs(json_data$objects[[1]]$confidence[2]-
                      json_data$objects[[1]]$confidence[1])
        
        confidence_diff_vector <- c(confidence_diff_vector, diff)
      }
    }
  }
  
  return(confidence_diff_vector)
}

confidences_test <- extract_confidence_differences("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1")

boxplot(confidences_test)
```

## 0.4 Merge data

```{r}
#dplyr::bind_rows() is more flexible than base::rbind(). Manages df within the df
data_04_to_06_07_2022 <- bind_rows(
  data_04_07_22,
  data_05_07_2022,
  data_06_07_2022_part1,
  data_06_07_2022_part2)
```

Keep only data between 8h and 21h :

```{r}
data_8h_21h_04_to_06_07_2022 <- rescale_8h_21h(data_04_to_06_07_2022)
```

Add a time variable which does not take into account the missing hours between
21h and 8h :

```{r}
data_8h_21h_04_to_06_07_2022_compressed_time <- add_compressed_time_variable(data_8h_21h_04_to_06_07_2022)
```

# 1. Switches between postures lying/sitting/standing

## 1.1 Number & proportion of each posture by time unit

### 1.1.1 Function

```{r}

# Frequency of postures lying/ sitting/ standing by timestep (chosen)
frequency_position <- function(data, interval_seconds) {
  data <- data %>% arrange(Date_Time) #sort by date
  
  start_time <- min(data$Date_Time)   #oldest frame
  end_time <- max(data$Date_Time)     #newest frame
  
  #cut between these 2 frames depending on the time interval
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(                       #create the new df
    start_time = intervals[-length(intervals)],  #drop the last time
    end_time = intervals[-1]                     #drop the first time
  )
  
  df_counts <- df_counts %>%
    rowwise() %>%               #for each line
    mutate(
      lying = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 0),            #count lying
      standing = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 1),            #count standing
      sitting = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 2),            #count sitting
      not_visible = sum(data$Date_Time >= start_time & data$Date_Time < end_time & data$class_id == 3)             #count not visible
    )
  
  return(df_counts)
}

# Test for 900 seconds (15 minutes)

frequency_position_04_07_2022 <- frequency_position(data = data_04_07_2022, interval_seconds = 600)

frequency_position_04_to_06_07_2022 <- frequency_position(data = data_8h_21h_04_to_06_07_2022, interval_seconds = 900)
```

### 1.1.2 Chart

```{r}
# library(ggplot2)
# library(tidyr)
# library(dplyr)

#put data in the long format (instead of wide) : pivot function
frequency_position_04_to_06_07_2022_PIVOT <- frequency_position_04_to_06_07_2022[,-2] %>% #drop the end_time column
  pivot_longer(
    cols = !start_time, 
    names_to = "Posture", 
    values_to = "Count"
  )

#chart
ggplot(data = frequency_position_04_to_06_07_2022_PIVOT,
       aes(fill = Posture, y = Count, x = start_time)) +         #start_time as x variable
  geom_bar(position = "stack", stat = "identity") +              #stacked bars, no %
  ggtitle("Fox4313's posture every 15min between days 04/07/2022 and 06/07/2022") +   #title
  xlab("Time of the day") +
  ylab("Amount of seconds spent in this posture") +                              
  scale_fill_manual(breaks = c("lying", "sitting", "standing", "not_visible"), #re-order legend
                    values = c("lying" = "lightgreen", #change legend colors
                               "sitting" = "orange",
                               "standing" = "tomato",
                               "not_visible" = "lightgrey"))
  
```

### 1.1.3 Chronologic series without 21h-8h gap

```{r}

# Getting all the postures in a single dataset

# Remove data between 21h-8h
frequency_position_8h_21h_04_to_06_07_2022 <- frequency_position_04_to_06_07_2022[hour(frequency_position_04_to_06_07_2022$start_time) >= 8 & hour(frequency_position_04_to_06_07_2022$start_time) < 21,]

# Pivot the data
frequency_position_8h_21h_04_to_06_07_2022_PIVOT <- frequency_position_8h_21h_04_to_06_07_2022 %>% 
  select (-end_time) %>%                #drop the end_time column
  pivot_longer(
    cols = !start_time, 
    names_to = "Posture", 
    values_to = "Count"
  )

# Add the compressed time : don't use the add_compressed_time_variable on pivot data ! Because 4 lines for each time period and not only 1 !
frequency_position_8h_21h_04_to_06_07_2022_PIVOT$compressed_time <- rep(0:((nrow(frequency_position_8h_21h_04_to_06_07_2022_PIVOT)-1) %/% 4), each = 4)

# Proportions : pour chaque groupe de temps on veut le Count divisé par le nombre de secondes, et le reste NA/ pas noté ?
frequency_position_8h_21h_04_to_06_07_2022_PIVOT$proportion <- frequency_position_8h_21h_04_to_06_07_2022_PIVOT$Count/(15*60)

```

Plots :

```{r}
# Counts
ggplot(frequency_position_8h_21h_04_to_06_07_2022_PIVOT,
       aes(x = compressed_time, y = Count)) +
  geom_line(aes(color= Posture)) +
  scale_color_manual(name = "Posture",
                     labels = c("Lying", "Sitting", "Standing", "Not visible"),
                     values = c("lying" = "lightgreen", #change legend colors
                               "sitting" = "orange",
                               "standing" = "tomato",
                               "not_visible" = "lightgrey"))

# Frequencies
ggplot(frequency_position_8h_21h_04_to_06_07_2022_PIVOT,
       aes(x = compressed_time, y = proportion)) +
  geom_line(aes(color= Posture)) +
  scale_color_manual(name = "Posture",
                     labels = c("Lying", "Sitting", "Standing", "Not visible"),
                     values = c("lying" = "lightgreen", #change legend colors
                               "sitting" = "orange",
                               "standing" = "tomato",
                               "not_visible" = "lightgrey"))
```

## 1.2 Movement score : quantify each posture & sum it

What we do have : 0 = lying, 1 = standing, 2 = sitting.

What we want : 0 = lying, 0.5 = sitting, 1 = standing (so that the max score =
1).

### 1.2.1 Function

```{r}
#Change posture code to lying-sitting-standing (instead of lying-standing-sitting)
recoding_posture <- function(data){
  data <- data %>% 
  mutate(increasing_code = case_when(name=="lying" ~ 0,
                                   name=="sitting" ~ 0.5,
                                   name=="standing" ~ 1,
                                   name=="not visible" ~ NA, #to avoid having it in the sum
                                   TRUE ~ NA))
}

#Test data 04/07/2022
data_8h_21h_04_to_06_07_2022_increasing_code <- recoding_posture(data_8h_21h_04_to_06_07_2022)
```

```{r}
# Amount activity function
amount_activity <- function(data, interval_seconds) {
  data <- data %>% arrange(Date_Time)
  
  start_time <- min(data$Date_Time)
  end_time <- max(data$Date_Time)
  
  intervals <- seq(from = start_time, to = end_time, by = interval_seconds)
  
  df_counts <- data.frame(
    interval_start = intervals[-length(intervals)],
    interval_end = intervals[-1]
  )
  
  df_counts <- df_counts %>%
    rowwise() %>%
    mutate(
      total_activity = sum(data$increasing_code[data$Date_Time >= interval_start & data$Date_Time < interval_end], na.rm = TRUE), #not counting NAs
      activity_proportion = ifelse(
        total_activity != 0,
        total_activity / nrow(data[data$Date_Time >= interval_start & data$Date_Time < interval_end, ]),
        0
      )
    )
  
  return(df_counts)
}


# Test every 900 seconds (15 minutes)
amount_activity_8h_21h_04_to_06_07_2022 <- amount_activity(data = data_8h_21h_04_to_06_07_2022_increasing_code,
                                              interval_seconds = 900)

```

### 1.2.2 Chronologic series

```{r}
# Compressed time variable to skip parts between 21h and 8h
amount_activity_8h_21h_04_to_06_07_2022_compressed_time <- add_compressed_time_variable(amount_activity_8h_21h_04_to_06_07_2022)

# Plot
ggplot(amount_activity_8h_21h_04_to_06_07_2022_compressed_time,
       aes(x = compressed_time, y = activity_proportion)) +
  geom_line() 
```

## 1.3 Amount of posture changes by time unit

### 1.3.1 Function

posture_no_na is a temporary variable : every not_visible & NA posture will be
replaced by the previous one. Useful only to count the amount of posture
changes.

```{r}
# Detect time changes
amount_posture_changes <- function(
    data,
    group_time){ #group_time : "number + unit" (among : second, minute, hour, day,                     week, month, bimonth, quarter, season, halfyear and year)
  
# Temporary variable : not_visible & NAs replaced by the latest posture (so wrong data, but useful to count the posture changes)
  data <- data %>% 
    mutate(posture_no_NA = case_when(
    #replace not_visible & NA by the latest
      name == "not_visible" ~ lag(name, default = first(name)),
      is.na(name) ~ lag(name, default = first(name)),
    #leave the others
      TRUE ~ name))
  
  # Detect position changes
  data_valid <- data %>%
    arrange(Date_Time) %>%  #Sort by date
    # Movement : if posture != posture at previous time (skip NAs & not_visible)
    mutate(Position_change = posture_no_NA != lag(posture_no_NA, default = first(posture_no_NA)))

  # Results
  return(changes_by_group_time(data_valid, time_gap = group_time))
  }


# Get the sum of posture changes by time unit
changes_by_group_time <- function(data, time_gap) {
  data %>%
    mutate(Time_group = floor_date(Date_Time, unit = time_gap)) %>% #make time groups
    group_by(Time_group) %>%
    summarise(Nb_changes = sum(Position_change, na.rm = TRUE)) %>% #sum changes
    ungroup()                                     #just in case
}


# Example : changes per minute & day
amount_changes_data_8h_21h_04_to_06_07_2022 <- amount_posture_changes(data_8h_21h_04_to_06_07_2022, "1 minute")
amount_posture_changes(data_8h_21h_04_to_06_07_2022, "1 day")
```

### 1.3.2 Chart

```{r}
# Skip parts between 21h and 8h

  # Add a new time variable to replace real time
add_compressed_time_variable <- function(data) {
  data$compressed_time <- seq_len(nrow(data))-1
  return(data)
}

  # Dataset
amount_changes_data_8h_21h_04_to_06_07_2022_compressed_time <- add_compressed_time_variable(amount_changes_data_8h_21h_04_to_06_07_2022)

# Plot
ggplot(amount_changes_data_8h_21h_04_to_06_07_2022_compressed_time,
       aes(x = compressed_time, y = Nb_changes)) +
  geom_line() +
  xlab("Temps entre 8h et 21h chaque jour") +
  ylab("Nombre de changements de position") +
  ggtitle("Changements de position du renard 4313", subtitle = "Du 4 au 6 juillet 2022, toutes les minutes")
```

# -----

# Maybe later : movement of the center of the box 

## 1 Frequency of movement of the center by time unit

```{r}
# Doesn't work yet

# Number of movements made by time interval 
movements_amount <- function(data, interval_seconds, movement_threshold = 0.01) {   data <- data %>% arrange(Date_Time) #sort by date      
start_time <- min(data$Date_Time)   #oldest frame   
end_time <- max(data$Date_Time)     #newest frame  

#cut between these 2 frames depending on the time interval   
intervals <- seq(from = start_time, to = end_time, by = interval_seconds)      
df_counts <- data.frame(                       #create the new df     
  start_time = intervals[-length(intervals)],  #drop the last time     
  end_time = intervals[-1]                     #drop the first time   
  )      
#movement yes/no :   
data <- data %>%      
  mutate(movement_yes_no = ifelse( #if position difference between 2 times > 0,01      
    abs(data$relative_coordinates$center_x - lag(data$relative_coordinates$center_x)) > movement_threshold      
    | abs(data$relative_coordinates$center_y - lag(data$relative_coordinates$center_y)) > movement_threshold ,           
    1,                              #then movement      
    0)                              #else : no movement)     
    )     df_counts <- df_counts %>%     
  rowwise() %>%    
  mutate(movement_counts = sum(data[data$Date_Time > start_time & data$Date_Time <= end_time,]$movement_yes_no, #amount of movements = sum of the 1 (= movements)                       
                               na.rm = T),  #to avoid the 1st NA        
         movement_proportion = ifelse(             
           nrow(data[data$Date_Time > start_time & data$Date_Time <= end_time,])!=0, #if there is at least 1 observation for this timestep             
           movement_counts/nrow(data[data$Date_Time > start_time & data$Date_Time <= end_time,]),   #proportion = n/N             
           0   #else : proportion = 0           
           )      
         )   
return(df_counts)  
}  

movement_04_to_06_07_2022 <- movements_amount(data = data_8h_21h_04_to_06_07_2022, interval_seconds = 3600)
```

```{r}
#code copilot, à voir 
calculate_distances <- function(data, interval) {      # Calculer la distance entre deux points   
  calculate_distance <- function(x1, y1, x2, y2) {     
    sqrt((x2 - x1)^2 + (y2 - y1)^2)   
    }      
  
  # Ajouter une colonne pour la distance parcourue chaque seconde   
  data <- data %>%     
    arrange(Date_Time) %>%     
    mutate(       
      distance = sqrt((relative_coordinates$center_x - lag(relative_coordinates$center_x))^2 +
                        (relative_coordinates$center_y - lag(relative_coordinates$center_y))^2),       
      time_diff = as.numeric(difftime(Date_Time, lag(Date_Time), units = "secs"))     ) %>%
    filter(!is.na(distance) & time_diff == 1)  #should not happen ?      
  
  # Calculer la somme des distances et la vitesse moyenne pour chaque intervalle   
  result <- data %>%     
    mutate(interval_group = floor(as.numeric(difftime(Date_Time, min(Date_Time), units = "secs")) / interval)) %>%     
    group_by(interval_group) %>%     
    summarise(       
      total_distance = sum(distance, na.rm = TRUE),       
      average_speed = total_distance / interval     
      )      
  return(result) 
  }  

# Exemple d'utilisation # 
data <- read.csv("path_to_your_data.csv") 
interval <- 60 # par exemple, 60 secondes 
result <- calculate_distances(data, interval) 
print(result) 

calculate_distances(data=data,interval=600) 
```

## 2 Movements' intensity

## 3 Movements' speed
