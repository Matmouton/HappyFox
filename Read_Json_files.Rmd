---
title: "Extraire des infos d'un Json"
author: "Mathilda Alhamadah"
date: "2025-04-01"
output:
  html_document:
    toc: true             #table des matières
    toc_float: true       #table des matières toujours visible
    theme: bootstrap      #changer le thème de la page
    highlight: zenburn    #changer le thème des chunks
    
editor_options: 
  markdown: 
    wrap: 80
---

# 1. Load packages & data {.tabset}

## 1.1 Packages & data

I used the **jsonlite** package.

```{r packages, message=FALSE, warning=FALSE}
library(jsonlite)
library(purrr)
library(curl)
library(dplyr)
library(lubridate)
library(tidyr)
library(ggplot2)
library(patchwork)
```

Run the whole chunk at the same time (WD & fromJSON).

```{r data_sample, message=FALSE}

#6 test data

setwd("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json") #Set WD

data_json_1 <- fromJSON("0308Efox4284-2023-02-02-16h08m11s045.png_pred.json") 
data_json_2 <- fromJSON("0308Mfox4284-2023-02-02-15h46m15s695.png_pred.json")
data_json_3 <- fromJSON("0308Mfox4284-2023-02-02-15h46m43s354.png_pred.json")
data_json_4 <- fromJSON("0308Mfox4284-2023-02-02-15h48m01s143.png_pred.json")
data_json_5 <- fromJSON("0308Mfox4284-2023-02-02-15h50m05s800.png_pred.json")
data_json_6 <- fromJSON("0308Mfox4284-2023-02-02-15h50m36s039.png_pred.json")

#10 files with 0, 1, 2, 3 and 4 predictions (2 files each). Same format than YOLO.

setwd("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_comme_YOLO")

data_json_real_1 <- fromJSON("c_f_FOX4383_05_07_2022_08_14_35_pred.json")
data_json_real_2 <- fromJSON("c_f_FOX4383_05_07_2022_10_12_05_pred.json")
data_json_real_3 <- fromJSON("c_f_FOX4383_05_07_2022_10_44_28_pred.json")
data_json_real_4 <- fromJSON("c_f_FOX4383_05_07_2022_12_41_19_pred.json")
data_json_real_5 <- fromJSON("c_f_FOX4383_05_07_2022_12_43_00_pred.json")
data_json_real_6 <- fromJSON("c_f_FOX4383_05_07_2022_14_38_20_pred.json")
data_json_real_7 <- fromJSON("c_f_FOX4383_05_07_2022_15_00_09_pred.json")
data_json_real_8 <- fromJSON("c_f_FOX4383_06_07_2022_16_52_43_pred.json")
data_json_real_9 <- fromJSON("c_f_FOX4383_06_07_2022_17_55_29_pred.json")
data_json_real_10 <- fromJSON("c_f_FOX4383_05_07_2022_17_31_40_pred.json")

```

## 1.2 Function to load data

```{r load_json_function}
#Function to load the data
load_json <- function(WD, file_name){
  
  #requirements :
            # WD & file_name are strings. 
  if (!is.character(WD) | !is.character(file_name)) {
    stop("Le working directory et le fichier doivent être des chaînes de caractère.")
  }
            # the file extension is .json
  if (!grepl("\\.json$", file_name)) {              #if the ending of the character is not ".json"
    stop("Le fichier doit être un fichier json.")   #stop
  }
  
  setwd(WD)                                #locate the data
  loaded_file <- fromJSON(file_name)       #load file
  return(loaded_file)                      #return file
}

#Test function
      #right file
datatest1 <- load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
                       file_name = "0308Efox4284-2023-02-02-16h08m11s045.png_pred.json")
datatest1[[1]] == data_json_real_1[[1]]  #Compare dataframes, [[1]] because there are 2 $objects in the json idk why

#       #wrong name_file type
# datatest1 <- load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
#                        file_name = 3)

#       #wrong name_file extension
# datatest1 <- load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
#                        file_name = "0308Efox4284-2023-02-02-16h08m11s045.png_pred.csv")

#clean up
rm(datatest1)


```

If no prediction available in the JSON file :

```{r}
#Chargement d'un Json vide pour voir 
empty_json <- load_json("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/1er_run_YOLO_10k_images", "c_f_FOX4383_06_07_2022_11_47_53_pred.json")

length(empty_json$objects[[1]])
length(data_json_1$objects[[1]])
```

If 2 predictions are available :

```{r}
#Chargement d'un json à 2 prédictions
nrow(data_json_real_10$objects[[1]])
nrow(data_json_real_1$objects[[1]]) #comparaison avec json à 1 prédiction
```

# 2. Function to keep only a single posture per second

Possible to select confidence threshold. Fox_id_limits is a vector of size 2
taking indexes of the 1st & the last part of the fox_id. Same for
date_time_limits.

[Example]{.underline} : for a filename like :
"blabla_fox4352_01_07_2023_14_36_02_blabla", we will have fox_id_limits =
c(11,14) and date_time_limits = c(16,34).

```{r}
# Function to keep only 1 posture per second

#Keep only one posture (= one line) per second

one_position_file <- function(
    json_file,
    threshold = 0.34,            #default = better prediction than random classification (=1/3 because there are 3 postures)
    fox_id_limits = c(8,11),     #default = YOLO output
    date_time_limits = c(13,31), #same
    date_time_format = "%d_%m_%Y_%H_%M_%S" ) { #same
  

  nb_pred <- length(json_file$objects[[1]]) #keep the number of predictions
  
#If Json file is not empty (there is at least 1 prediction)
  if(nb_pred >0) {
    
    nb_pred <- nrow(json_file$objects[[1]])  #get how many predictions are made by YOLO
    
    #Get file and most reliable prediction 
    
  #isolate the df with posture lines + sort by confidence (higher on line 1)
    dataframe_postures <- json_file$objects[[1]] %>% 
      arrange(desc(confidence))
  #identify the most reliable posture
    posture_most_confidence <- dataframe_postures[1,]
    
  #identify the 2nd most reliable posture (if existing)
    posture_2nd_most_confidence <- ifelse(nb_pred >= 2,
                                          dataframe_postures[2,],
                                          NA) #if <2 pred : no 2nd posture
  #new dataset with only the most confident prediction (1 line)
    data_new <- posture_most_confidence  #get the most confident line
    
    #get the gap between the 2 most reliable predictions (if there are 2)
      data_new <- data_new %>% 
        mutate(
          confidence_gap = case_when(
          #if only 1 prediction : confidence_gap = 1 (highest certainty gap)
            nb_pred == 1 ~ 1, 
          #if 2+ predictions : confidence_gap = difference btw 2 highest pred
            nb_pred >= 2 ~ dataframe_postures[1, "confidence"] - dataframe_postures[2, "confidence"]),
          
      #get number of predictions
          number_of_predictions = nb_pred)

    #Check reliability
    if (max(json_file$objects[[1]]$confidence) < threshold){  #No line reliable enough
      print(paste("Confidence <", threshold*100, "% for file", json_file$filename,". Change threshold or do human check.")) #Change threshold/ human check
      
    }
    
# If Json file is empty (0 predictions)
  }else{
    data_new <- json_file                           #no change needed
    data_new <- data.frame(class_id = 3,            #position number 3
                           name = "not visible",    #position name = not visible
                           relative_coordinates = NA, #no coordinates
                           confidence = NA,           #no confidence
                           confidence_gap = NA,       #no confidence gap
                           number_of_predictions = 0) #no predictions
  }
  
#In any situation (if Json file is/is not empty)
    #add the filename
    data_new <- data_new %>%
      mutate(filename = json_file$filename) #get filename
    
    #get the date and time
    str_datetime <- substr(data_new$filename, date_time_limits[1], date_time_limits[2]) #get the datetime part from the string
    
    date_wrong_format <- strptime(str_datetime, format = date_time_format) #change the date into a datetime format (but not the right one : default)
    
    great_date <- format(date_wrong_format, "%d/%m/%Y %H:%M:%S") #date & hour in the right format
    
    great_date <- as.POSIXct(great_date, format = "%d/%m/%Y %H:%M:%S") #convert it into POSIXct (a great format for datetime data)
    
    data_new <- data_new %>% 
      mutate(Date_Time = great_date) #add variable
    
   #get the fox id
    fox_id <- substr(data_new$filename, fox_id_limits[1], fox_id_limits[2])
    
    data_new <- data_new %>% 
      mutate(fox_id = fox_id)        #add variable

    
   #output  
    return(data_new = data_new)  

}


# Tests

  #with 1 line file
one_position_file(data_json_1,
                  fox_id_limits = c(9,12),
                  date_time_limits = c(14,32),
                  date_time_format = "%Y-%m-%d-%Hh%Mm%S") #still working for a non-empty file

  #with empty file
one_position_file(empty_json,
                  fox_id_limits = c(8,11),
                  date_time_limits = c(13,31),
                  date_time_format = "%d_%m_%Y_%H_%M_%S")

one_position_file(data_json_real_1,
                  fox_id_limits = c(8,11),
                  date_time_limits = c(13,31),
                  date_time_format = "%d_%m_%Y_%H_%M_%S")

  #with 2 lines file
one_position_file(data_json_real_10,               
                  fox_id_limits = c(8,11),
                  date_time_limits = c(13,31),
                  date_time_format = "%d_%m_%Y_%H_%M_%S")

  #with 3 lines file
one_position_file(load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
                            file_name = "0308Efox4284-2023-02-02-16h08m11s045.png_pred.json"),
                  fox_id_limits = c(9,12),
                  date_time_limits = c(14,32),
                  date_time_format = "%Y-%m-%d-%Hh%Mm%S")
```

# 3. Put every second in the same dataframe

```{r merge_postures_function}
# Automatically merge all the files in a single dataframe

merge_postures <- function(list_df_postures) {
  return (dplyr::bind_rows(list_df_postures))
}


  # Test

# Create single lines
line1 <- one_position_file(
  load_json("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin",
            "0308Efox4284-2023-02-02-16h08m11s045.png_pred.json"))

line2 <- one_position_file(
  load_json("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin",
            "0308Mfox4284-2023-02-02-15h46m15s695.png_pred.json"))

line3 <- one_position_file(
  load_json("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin",
            "0407Afox4284-2023-02-02-09h58m22s726.png_pred.json"))


# Merge them
list_test <- list(line1, line2, line3)
df_final <- merge_postures(list_test)       #working

# Test with empty JSONs

Test
line1 <- one_position_file(data_json_1,
                  fox_id_limits = c(9,12),
                  date_time_limits = c(14,32),
                  date_time_format = "%Y-%m-%d-%Hh%Mm%S") #still working for a non-empty file
line2 <- one_position_file(empty_json,
                  fox_id_limits = c(8,11),
                  date_time_limits = c(13,31),
                  date_time_format = "%d_%m_%Y_%H_%M_%S")

merge_postures(list(line1, line2))

# Nettoyage
rm(list_test, line1, line2, line3, line4, line5, line6, data_json_1, data_json_2, data_json_3, data_json_4, data_json_5, data_json_6)
```

# 4. From JSON files to dataframe

Automatize all of the above functions into a single one :

```{r from_json_to_df_function}

from_json_to_df <- function(WD,
                            threshold = 0.34,          #being better than random
                            fox_id_limits = c(8,11),   #default = YOLO output
                            date_time_limits = c(13,31),                #same
                            date_time_format = "%d_%m_%Y_%H_%M_%S")  {  #same
  
  # Get all the JSON files from the folder
  setwd(WD)                              #Set WD
  files <- list.files(pattern = ".json") #get Json files
  print(paste("Chargement terminé. ",length(files), " fichiers ont été chargés."))
  
  # Create empty list of dataframes & variable to increment
  list_df1line = list()  #empty list
  i = 0                  #increment
  
  # Loop for each file
  for (file in files) {
    
    # Apply function load_json to every file of the folder
    data_loaded <- load_json(WD = WD, file = file)
    
    # Apply function one_position_file to every new dataframe
    data_1line <- one_position_file(json_file = data_loaded,
                                    threshold = threshold,
                                    fox_id_limits = fox_id_limits,
                                    date_time_limits = date_time_limits,
                                    date_time_format = date_time_format)
  
    # Put them all in a list
    list_df1line[[i+1]] <- data_1line
    
    i <- i+1 #next file
  }
  
  # Merge this list's elements & get the dataframe
  df_merged <- merge_postures(list_df1line) 
  

  # Print end of the run
  print(paste("Extraction terminée. ", i, "fichiers ont été fusionnés."))
  
  # Spot files with NA date (check if they are prediction files, 1 of them is created at every YOLO run)
  print(paste("Il y avait", nrow(df_merged[is.na(df_merged$Date_Time),]), "fichiers sans date. Il s'agit des fichiers : ", df_merged[is.na(df_merged$Date_Time),]$filename))
  
  # Delete those files
  df_merged <- df_merged[!is.na(df_merged$Date_Time),]
  
  # Return data
  return(df_merged)
  
}
```

```{r test_function_json_to_df}

#test function for this file format (output of Marcin's app) : f_IDxxxx_dd_mm_yyyy_hh_mm_ss.jpg
df_test <- from_json_to_df("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin")

df_test  #Working !

#test function for other files format : 0308Efox4284-2023-02-02-16h08m11s045.png
df_test2 <- from_json_to_df("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
                            fox_id_limits = c(9,12),
                            date_time_limits = c(14,32),
                            date_time_format = "%d_%m_%Y_%H_%M_%S")

#Remove useless objects
rm(data_json_real_1, data_json_real_2, data_json_real_3, data_json_real_4,
   data_json_real_5, data_json_real_6, data_json_real_7, data_json_real_8,
   data_json_real_9, data_json_real_10,data_json_real_11, data_json_real_12,
   data_json_real_13, df_test, df_test2, df_final, empty_json)
```

```{r test_on_real_data}
#Test on small sample of real data (86 files)
data_test <- from_json_to_df("C:/Users/m.alhamadah/Desktop/test_json",
                             threshold = 0.34,
                             fox_id_limits = c(8,11),
                             date_time_limits = c(13,31),
                             date_time_format = "%d_%m_%Y_%H_%M_%S")

#Test2
test <- from_json_to_df("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Try",
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")

# Test with empty JSONs
df_test <- from_json_to_df("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/1er_run_YOLO_10k_images",
                          threshold = 0.33,
                          fox_id_limits = c(8,11),   #default = for the app outputs
                          date_time_limits = c(13,31),                #same
                          date_time_format = "%d_%m_%Y_%H_%M_%S")

```

/!\\ Not the same date as in the filename because I changed a bit the files so
that the days can vary (I used JSON files of only 1 day so I wanted to make it
vary a bit).

### → Boxplots of confidence difference between 2 prédictions (for the same frame)

If a frame gets 2 or 3 predictions from YOLO, does it make the highest
confidence lower ?

```{r}
#Highest confidence rate when there is :

#1 prediction
mean(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence) #0.94
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 1,]$confidence)

#2 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence) #0.77
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence)

#3 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence) #0.54
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence)

```

=\> Yes

Descriptive statistics of confidence gap when 2 predictions :

```{r}
library(jsonlite)

extract_confidence_differences <- function(directory) {
  
  # For all the Json files in the directory 
  files <- list.files(path = directory, pattern = "\\.json$", full.names = TRUE)
  confidence_diff_vector <- c() #empty vector
  
  for (file in files) {
    json_data <- fromJSON(file)
    
    # If Json not empty
    if (length(json_data$objects[[1]])>0) { 
      objects <- json_data$objects[[1]]
      n_objects <- nrow(objects)
      
      # If 2 predictions exactly
      if (n_objects == 2) {
        
        # Compute confidence difference
        diff <- abs(json_data$objects[[1]]$confidence[2]-
                      json_data$objects[[1]]$confidence[1])
        
        # Put it in a vector
        confidence_diff_vector <- c(confidence_diff_vector, diff)
      }
    }
  }
  # Return it
  return(confidence_diff_vector)
}

confidences_test <- extract_confidence_differences("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1")

# Boxplot
boxplot(confidences_test)
```

# 5. Aggregate several days & filter between 8h and 21h

/!\\ Check if the id_fox is always the same, if not : set it manually !

```{r}
#data$fox_id <- "4313"
```

Aggregate dataframes :

```{r}
#dplyr::bind_rows() is more flexible than base::rbind(). We need flexibility because there are dataframes within the dataframe.

data_04_to_06_07_2022 <- bind_rows(data_04_07_2022, data_05_07_2022, data_06_07_2022)

```

Adapt dataframe so that there is only (and mandatory) data between 8h and 21h.
No matter if we have to create NAs/ loose data.

```{r function_rescale_8h_21h}
rescale_8h_21h <- function(data){

# Keep only frames between 8am and 9pm
data_8h_21h_missing_seconds <- data %>%
  filter(format(Date_Time, "%H:%M:%S") >= "08:00:00" & format(Date_Time, "%H:%M:%S") <= "21:00:00")

# Create every second between 8am and 9pm for every fox id and day of recording
complete_data <- data_8h_21h_missing_seconds %>%
  mutate(date = as.Date(Date_Time)) %>%
  group_by(fox_id, date) %>%
  reframe(Date_Time = seq(from = as.POSIXct(paste(date[1], "08:00:00")),
                          to   = as.POSIXct(paste(date[1], "21:00:00")),
                          by   = "1 sec"))

# Merge it to the original data
data_8h_21h <- complete_data %>%
  left_join(data_8h_21h_missing_seconds, by = c("fox_id", "Date_Time"))


return (data_8h_21h)
  
}
```

# 6. Add variable to replace time so that we can skip the unavailable part between 21h and 8h.

We just want the line index. Make sure that the dataset is sorted by date.

```{r function_add_compressed_time_variable}
# Function
add_compressed_time_variable <- function(data) {
  data$compressed_time <- seq_len(nrow(data))-1 #-1 to make it start with 0
  return(data)
}

# Test
#data_8h_21h_04_to_06_07_2022_compressed_time <- add_compressed_time_variable(data_8h_21h_04_to_06_07_2022)
```

# 7. Remove inoculation times

```{r}
# Load all the data we have
load("data_8h_21h_03_08_2022.RData")
load("data_8h_21h_04_to_14_07_2022.RData")
load("data_8h_21h_05_to_08_08_2022.RData")

# Merge it
data_8h_21h_04_07_to_08_08_2022 <- bind_rows(data_8h_21h_04_to_14_07_2022, data_8h_21h_03_08_2022, data_8h_21h_05_to_08_08_2022)
```


We want to remove the whole day 04/07/22 and a part of the day 08/07/2022 (from
9h6m57s to 10h14m19).

```{r}
load("data_8h_21h_04_07_to_08_08_2022.Rdata")

data_8h_21h_05_07_to_08_08_2022 <- data_8h_21h_04_07_to_08_08_2022 %>% 
  filter(date != "2022-07-04") %>%  #remove first day
  filter(Date_Time < "2022-07-08 9:06:57" | Date_Time > "2022-07-08 10:14:09") #remove inoculation time
  
```

# 8. Remove uncertain data

Uncertain data = data with 1 prediction & confidence \> 1/3 or data with \> 1
predictions & confidence \> 1/3 & at least 0.2 confidence_gap between the 2 most
reliable predictions.

```{r}
reliable_data_8h_21h_05_07_to_08_08_2022 <- data_8h_21h_05_07_to_08_08_2022 %>% 
           #if only 1 prediction : keep only data with a confidence >= 0.34
  filter((number_of_predictions == 1 & confidence >= 0.34) | 
           #if >1 predictions : keep only data with  a confidence >= 0.34 & a gap >0.2 between the 2 best predictions' confidences
           (number_of_predictions >1 & confidence >= 0.34 & confidence_gap >= 0.2) |
           #keep the NA values also
           is.na(confidence_gap))
```
