---
title: "Extraire des infos d'un Json"
author: "Mathilda Alhamadah"
date: "2025-04-01"
output:
  html_document:
    toc: true             #table des matières
    toc_float: true       #table des matières toujours visible
    theme: bootstrap      #changer le thème de la page
    highlight: zenburn    #changer le thème des chunks
    
editor_options: 
  markdown: 
    wrap: 80
---

# 1. Chargement des packages & des données {.tabset}

## 1.1 Packages et données

Le package utile : **jsonlite**

```{r packages, message=FALSE, warning=FALSE}
#install.packages("jsonlite")
#install.packages("curl")
library(jsonlite)
library(purrr)
library(curl)
library(dplyr)
```

```{r data_sample, message=FALSE}
#Run tout le chunk en 1 fois 
setwd("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json")        #Set WD

data_json_1 <- fromJSON("0308Efox4284-2023-02-02-16h08m11s045.png_pred.json") #Load data
data_json_2 <- fromJSON("0308Mfox4284-2023-02-02-15h46m15s695.png_pred.json")
data_json_3 <- fromJSON("0308Mfox4284-2023-02-02-15h46m43s354.png_pred.json")
data_json_4 <- fromJSON("0308Mfox4284-2023-02-02-15h48m01s143.png_pred.json")
data_json_5 <- fromJSON("0308Mfox4284-2023-02-02-15h50m05s800.png_pred.json")
data_json_6 <- fromJSON("0308Mfox4284-2023-02-02-15h50m36s039.png_pred.json")

setwd("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1") #Json files directly from YOLO

  
data_json_real_1 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_42_pred.json") # 9 classic files
data_json_real_2 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_43_pred.json")
data_json_real_3 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_44_pred.json")
data_json_real_4 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_45_pred.json")
data_json_real_5 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_46_pred.json")
data_json_real_6 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_47_pred.json")
data_json_real_7 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_48_pred.json")
data_json_real_8 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_49_pred.json")
data_json_real_9 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_41_pred.json")

data_json_real_10 <- fromJSON("c_f_FOX4383_04_07_2022_10_57_41_pred.json") # 4 files with 2 pred.
data_json_real_11 <- fromJSON("c_f_FOX4383_04_07_2022_10_59_04_pred.json")
data_json_real_12 <- fromJSON("c_f_FOX4383_04_07_2022_11_04_48_pred.json")
data_json_real_13 <- fromJSON("c_f_FOX4383_04_07_2022_11_05_53_pred.json")


```

## 1.2 Fonction chargement des données

On fait le load dans une fonction pour pouvoir l'automatiser :

```{r load_json_function}
#Function to load the data
load_json <- function(WD, file_name){
  
  #requirements :
            # WD & file_name are strings. 
  if (!is.character(WD) | !is.character(file_name)) {
    stop("Le working directory et le fichier doivent être des chaînes de caractère.")
  }
            # the file extension is .json
  if (!grepl("\\.json$", file_name)) {              #if the ending of the character is not ".json"
    stop("Le fichier doit être un fichier json.")   #stop
  }
  
  setwd(WD)                                #locate the data
  loaded_file <- fromJSON(file_name)       #load file
  return(loaded_file)                      #return file
}


#Test function
      #right file
datatest1 <- load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
                       file_name = "0308Efox4284-2023-02-02-16h08m11s045.png_pred.json")
datatest1[[1]] == data_json_real_1[[1]]  #Compare dataframes, [[1]] because there are 2 $objects in the json idk why

      #wrong name_file type
# datatest1 <- load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
#                        file_name = 3)

      #wrong name_file extension
# datatest1 <- load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
#                        file_name = "0308Efox4284-2023-02-02-16h08m11s045.png_pred.csv")

#clean up
rm(datatest1)
```

# 2. Fonction pour garder qu'une position à chaque fois {.tabset}

Sélection possible du seuil de confiance. Fox_id_limits est un vecteur de taille
2 qui prend la position de la première et de la dernière partie de l'identifiant
du renard. Pareil pour date_time_limits.

[Exemple]{.underline} : pour un filename de la forme
"blabla_fox4352_01_07_2023_14_36_02_blabla", on aura fox_id_limits = c(11,14) et
date_time_limits = c(16,34).

Attention !! Cette fonction a été faite pour lire les noms de fichiers au format
de ceux sortis par l'appli de Marcin ! Elle ne fonctionnera pas avec un autre
format de nom de fichier, il faudra l'adapter !

Normalement les fichiers Json qu'on charge ont un élément "objects" qui a une
taille de 1\*4, 2\*4 ou 3\*4 selon combien il y a de prédictions pour cette
frame. Mais si aucune prédiction n'est faite, objects est vide :

```{r}
#Chargement d'un Json vide pour voir 
empty_json <- load_json("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/1er_run_YOLO_10k_images", "c_f_FOX4383_06_07_2022_11_47_53_pred.json")

length(empty_json$objects[[1]])
length(data_json_1$objects[[1]])
```

```{r}
#Chargement d'un json à 2 prédictions
nrow(data_json_real_10$objects[[1]])
nrow(data_json_real_1$objects[[1]]) #comparaison avec json à 1 prédiction
```

Du coup on adapte la fonction one_position_file pour que si on a un json vide,
on mette des NA partout sauf dans le filename :

```{r}
one_position_file <- function(json_file,
                              threshold = 0.5,        #default = arbitrary
                              fox_id_limits = c(5,8), #default = like in the app
                              date_time_limits = c(10,28), #same remark
                              date_time_format = "%d_%m_%Y_%H_%M_%S" ) { #same remark
  
  #If Json file is not empty (there is a prediction)
  if(length(json_file$objects[[1]])>0) {
    
    nb_pred <- nrow(json_file$objects[[1]])  #get how many predictions are made by YOLO
    
    #Get file and most reliable prediction  
    dataframe_postures <- json_file$objects[[1]]                        #isolate the df with posture lines
    posture_most_confidence <- which.max(dataframe_postures$confidence) #identify most reliable posture
    data_new <- dataframe_postures[posture_most_confidence,] #new dataset with only the line that has the higher threshold
    
    data_new <- data_new %>% 
      mutate(number_of_predictions = nb_pred)      #get number of predictions
    
    #Check reliability
    if (max(json_file$objects[[1]]$confidence) < threshold){  #No line reliable enough
      print(paste("Confidence <", threshold*100, "% for file", json_file$filename,". Change threshold or do human check.")) #Change threshold/ human check
    }   
    
  }else{
    data_new <- json_file    #if empty Json : no change needed
    data_new <- data.frame(class_id = 3,            #position number 3
                           name = "not visible",    #position name = not visible
                           relative_coordinates = NA,
                           confidence = NA,
                           number_of_predictions = 0)
  }
  
  #In any situation (if Json file is/is not empty)
    #add the filename
    data_new <- data_new %>%
      mutate(filename = json_file$filename) #get filename
    
    #get the date and time
    str_datetime <- substr(data_new$filename, date_time_limits[1], date_time_limits[2]) #bonne partie de la string
    #/!\ à changer si la forme du fichier change. Là c'est pour des fichiers type f_ID4384_03_02_2023_19_46_12.jpg uniquement
    
    date_wrong_format <- strptime(str_datetime, format = date_time_format) #transformé en date et heure
    
    great_date <- format(date_wrong_format, "%d/%m/%Y %H:%M:%S") #date & heure au bon format
    
    great_date <- as.POSIXct(great_date, format = "%d/%m/%Y %H:%M:%S") #mettre en format datetime
    
    data_new <- data_new %>% 
      mutate(Date_Time = great_date)
    
   #get the fox id
    fox_id <- substr(data_new$filename, fox_id_limits[1], fox_id_limits[2])
    #/!\ ça aussi ça peut changer si format filenamechange
    
    data_new <- data_new %>% 
      mutate(fox_id = fox_id)
    
   #output  
    return(data_new = data_new)  #attention : il est renvoyé mais pas stocké ! 

}

# Tests

  #with 1 line file
one_position_file(data_json_1,
                  fox_id_limits = c(9,12),
                  date_time_limits = c(14,32),
                  date_time_format = "%Y-%m-%d-%Hh%Mm%S") #still working for a non-empty file

  #with empty file
one_position_file(empty_json,
                  fox_id_limits = c(8,11),
                  date_time_limits = c(13,31),
                  date_time_format = "%d_%m_%Y_%H_%M_%S")

  #with 2 lines file
one_position_file(data_json_real_10,               
                  fox_id_limits = c(8,11),
                  date_time_limits = c(13,31),
                  date_time_format = "%d_%m_%Y_%H_%M_%S")

  #with 3 lines file
one_position_file(load_json(WD = "F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
                            file_name = "0308Efox4284-2023-02-02-16h08m11s045.png_pred.json"),
                  fox_id_limits = c(9,12),
                  date_time_limits = c(14,32),
                  date_time_format = "%Y-%m-%d-%Hh%Mm%S")
```

# 3. Fonction pour concaténer les lignes des positions dans un seul dataframe {.tabset}

## 3.2 Cas général : automatisation via une fonction

```{r merge_postures_function}
# Fonction pour merge automatiquement toutes les lignes des dataframes en un seul dataframe
merge_postures <- function(list_df_postures) {
  return (dplyr::bind_rows(list_df_postures))
}

# Création de lignes isolées pour l'exemple
line1 <- one_position_file(
  load_json("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin",
            "0308Efox4284-2023-02-02-16h08m11s045.png_pred.json"))

line2 <- one_position_file(
  load_json("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin",
            "0308Mfox4284-2023-02-02-15h46m15s695.png_pred.json"))

line3 <- one_position_file(
  load_json("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin",
            "0407Afox4284-2023-02-02-09h58m22s726.png_pred.json"))


# Test 
list_test <- list(line1, line2, line3)
df_final <- merge_postures(list_test)       #working

# Nettoyage
rm(list_test, line1, line2, line3, line4, line5, line6, data_json_1, data_json_2, data_json_3, data_json_4, data_json_5, data_json_6)
```

Test with empty Json : working !

```{r}
# Test
# line1 <- one_position_file(data_json_1,
#                   fox_id_limits = c(9,12),
#                   date_time_limits = c(14,32),
#                   date_time_format = "%Y-%m-%d-%Hh%Mm%S") #still working for a non-empty file
# line2 <- one_position_file(empty_json,
#                   fox_id_limits = c(8,11),
#                   date_time_limits = c(13,31),
#                   date_time_format = "%d_%m_%Y_%H_%M_%S")
# 
# merge_postures(list(line1, line2))
```

# 4. Fonction du fichier Json au dataframe {.tabset}

On automatise tout ça dans une fonction :

```{r from_json_to_df_function}

from_json_to_df <- function(WD,
                            threshold = 0.34,          #being better than random
                            fox_id_limits = c(8,11),   #default = YOLO output
                            date_time_limits = c(13,31),                #same
                            date_time_format = "%d_%m_%Y_%H_%M_%S")  {  #same
  
  # Récuperer tous les fichiers Json du dossier
  setwd(WD)        #Set WD
  files <- list.files(pattern = ".json") #get Json files
  print(paste("Chargement terminé. ",length(files), " fichiers ont été chargés."))
  
  # Créer la liste vide de dataframes et la variable à incrémenter
  list_df1line = list()  #empty list
  i = 0  #increment
  
  # Boucle pour chaque fichier
  for (file in files) {
    
    # Appliquer la fonction load_json à tous les éléments du dossier
    data_loaded <- load_json(WD = WD, file = file)
    
    # Appliquer one_position_file à tous les nouveaux dataframes
    data_1line <- one_position_file(json_file = data_loaded,
                                    threshold = threshold,
                                    fox_id_limits = fox_id_limits,
                                    date_time_limits = date_time_limits,
                                    date_time_format = date_time_format)
  
    # Tous les mettre dans une liste 
    list_df1line[[i+1]] <- data_1line
    
    i <- i+1 #next file
  }
  
  # Appliquer le merge sur la liste et récup le dataframe mergé
  df_merged <- merge_postures(list_df1line) 
  

  # Afficher la fin du run
  print(paste("Extraction terminée. ", i, "fichiers ont été fusionnés."))
  
  # Spotter les fichiers de date NA (vérif qu'il s'agit des fichiers predictions.jpg créés à chaque lancement de YOLO)
  print(paste("Il y avait", nrow(df_merged[is.na(df_merged$Date_Time),]), "fichiers sans date. Il s'agit des fichiers : ", df_merged[is.na(df_merged$Date_Time),]$filename))
  
  # Supprimer ces fichiers
  df_merged <- df_merged[!is.na(df_merged$Date_Time),]
  
  return(df_merged)
  
}
```

```{r test_function_json_to_df}

#test function for app files format : f_IDxxxx_dd_mm_yyyy_hh_mm_ss.jpg
df_test <- from_json_to_df("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/Json_test_comme_app_marcin")

df_test  #Working !
df_final #Pour comparer avec ce qui avait été fait manuellement : même chose

#test function for other files format : 0308Efox4284-2023-02-02-16h08m11s045.png
df_test2 <- from_json_to_df("F:/stagiaire/2025_ALHAMADAH_Mathilda_HappyFox/script_R/json",
                            fox_id_limits = c(9,12),
                            date_time_limits = c(14,32),
                            date_time_format = "%d_%m_%Y_%H_%M_%S")

```

```{r remove_useless_objects}
rm(data_json_real_1,
   data_json_real_2,
   data_json_real_3,
   data_json_real_4,
   data_json_real_5,
   data_json_real_6,
   data_json_real_7,
   data_json_real_8,
   data_json_real_9,
   data_json_real_10,
   data_json_real_11,
   data_json_real_12,
   data_json_real_13,
   df_test,
   df_test2,
   df_final,
   empty_json)
```

```{r test_on_real_data}
#Test on real data from YOLO (29000 files)
  # data_04_07_22 <- from_json_to_df("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1",
  #                 threshold = 0.34,
  #                 fox_id_limits = c(8,11),
  #                 date_time_limits = c(13,31),
  #                 date_time_format = "%d_%m_%Y_%H_%M_%S")
  # 
  # data_04_07_22

#Test on small sample of real data (86 files)
data_test <- from_json_to_df("C:/Users/m.alhamadah/Desktop/test_json",
                             threshold = 0.34,
                             fox_id_limits = c(8,11),
                             date_time_limits = c(13,31),
                             date_time_format = "%d_%m_%Y_%H_%M_%S")

#Test2
test <- from_json_to_df("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Try",
                        fox_id_limits = c(8,11),
                        date_time_limits = c(13,31),
                        date_time_format = "%d_%m_%Y_%H_%M_%S")
```

/!\\ Pas de panique : on n'a pas toutes les lignes dans le df_final parce que
c'était long alors j'en ai mis que 3 sur les 10. Et on n'a pas la même date que
dans le titre du fichier pour le df_test parce que c'était le même jour tout le
temps alors pour varier j'ai changé le filename DANS LE JSON. Si on compare avec
le Json tout est bon.

```{r}
#Afficher les formats de filenames qui vont pas :
wrong_id <- df_test2$filename[which(is.na(df_test2$Date_Time) | is.na(df_test2$fox_id))]
wrong_id
```

Des fois on a des Json avec les objets vides parce qu'on n'a pas de prédiction
de la part de YOLO. Dans ces cas. On a quand même le filename donc on peut récup
la date et l'id renard. Donc on veut juste rajouter une variable de position qui
vaut "hidden" quand le renard n'est pas visible, et où on a quand même des
données pour Datetime et id renard. On aura juste des NA pour les 4 variables de
position x et y.

```{r from_json_to_df_empty_json}
df_test <- from_json_to_df("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/1er_run_YOLO_10k_images",
                          threshold = 0.33,
                          fox_id_limits = c(8,11),   #default = for the app outputs
                          date_time_limits = c(13,31),                #same
                          date_time_format = "%d_%m_%Y_%H_%M_%S")
```

### 4.1 Boxplots de la différence de conf entre 2 prédictions (pour la même frame)

```{r}
#Highest confidence rate when there is :

#3 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence) #0.54
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 3,]$confidence)

#2 predictions
mean(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence) #0.77
boxplot(data_04_07_22[data_04_07_22$number_of_predictions == 2,]$confidence)
```

Adding descriptive statistics of confidence when 2 predictions :

```{r}
library(jsonlite)

extract_confidence_differences <- function(directory) {
  files <- list.files(path = directory, pattern = "\\.json$", full.names = TRUE)
  confidence_diff_vector <- c()
  
  for (file in files) {
    json_data <- fromJSON(file)
    
    if (length(json_data$objects[[1]])>0) {   #if Json not empty
      objects <- json_data$objects[[1]]
      n_objects <- nrow(objects)
      
      # Si 2 prédictions exactement
      if (n_objects == 2) {
        
        diff <- abs(json_data$objects[[1]]$confidence[2]-
                      json_data$objects[[1]]$confidence[1])
        
        confidence_diff_vector <- c(confidence_diff_vector, diff)
      }
    }
  }
  
  return(confidence_diff_vector)
}

confidences_test <- extract_confidence_differences("F:/projet/2024_HAPPY_FOX/donnee/stage_mathilda/Cropped_images_complete/renard4313 Video 1 04_07_2022 10_47_16 1")

boxplot(confidences_test)
```

# 5. Agréger plusieurs jours et filtrer entre 8h et 21h

On peut agréger facilement les dataframes :

```{r}
data_04_to_06_07_2022 <- rbind(data_04_07_2022, data_05_07_2022, data_06_07_2022)
```

On peut ensuite filtrer le dataframe merge pour qu'il ne contienne que des
données entre 8h et 21h, et qu'il créé les secondes manquantes le cas échéant :

```{r}
# Keep only frames between 8am and 9pm
data_8h_21h_04_to_06_07_2022_missing_seconds <- data_04_to_06_07_2022 %>%
  filter(format(Date_Time, "%H:%M:%S") >= "08:00:00" & format(Date_Time, "%H:%M:%S") <= "21:00:00")

# Create every second between 8am and 9pm for every fox id and day of recording
complete_df <- data_04_to_06_07_2022_8h_21h %>%
  mutate(date = as.Date(Date_Time)) %>%
  group_by(fox_id, date) %>%
  reframe(Date_Time = seq(from = as.POSIXct(paste(date[1], "08:00:00")),
                          to   = as.POSIXct(paste(date[1], "21:00:00")),
                          by   = "1 sec"))

# Merge it to the original data
data_8h_21h_04_to_06_07_2022 <- complete_df %>%
  left_join(data_8h_21h_04_to_06_07_2022_missing_seconds, by = c("fox_id", "Date_Time"))

rm(data_8h_21h_04_to_06_07_2022_missing_seconds, complete_df)
```

Fonction :

```{r function_rescale_8h_21h}
rescale_8h_21h <- function(data){

# Keep only frames between 8am and 9pm
data_8h_21h_missing_seconds <- data %>%
  filter(format(Date_Time, "%H:%M:%S") >= "08:00:00" & format(Date_Time, "%H:%M:%S") <= "21:00:00")

# Create every second between 8am and 9pm for every fox id and day of recording
complete_data <- data_8h_21h_missing_seconds %>%
  mutate(date = as.Date(Date_Time)) %>%
  group_by(fox_id, date) %>%
  reframe(Date_Time = seq(from = as.POSIXct(paste(date[1], "08:00:00")),
                          to   = as.POSIXct(paste(date[1], "21:00:00")),
                          by   = "1 sec"))

# Merge it to the original data
data_8h_21h <- complete_data %>%
  left_join(data_8h_21h_missing_seconds, by = c("fox_id", "Date_Time"))


return (data_8h_21h)
  
}

```

# 6. Ajouter une variable qui remplace le temps pour sauter les vides de 21h à 8h

On a un jeu de données qui passe automatiquement de 21h à 8h le lendemain. Donc
le "temps compressé" qu'on veut, qui supprime les temps entre 21h et 8h, est
exactement le numéro de chaque ligne. Il suffit d'enlever 1 si on veut que ce
temps commence à 0.

```{r function_add_compressed_time_variable}
add_compressed_time_variable <- function(data) {
  data$compressed_time <- seq_len(nrow(data))-1 #-1 to make it start with 0
  return(data)
}


#test2 <- add_compressed_time_variable(data_8h_21h_04_to_06_07_2022)
```
